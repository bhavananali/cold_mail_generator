{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSEARR_EHB4s"
      },
      "outputs": [],
      "source": [
        "!pip install langchain -q\n",
        "!pip install openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12P_MUojHGLd",
        "outputId": "a7c6152c-c7ee-4d1f-b9be-b50e1862113f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/408.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm=ChatGroq(\n",
        "    temperature=0,\n",
        "    groq_api_key='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',\n",
        "    model_name='llama-3.1-70b-versatile'\n",
        ")\n",
        "response=llm.invoke('What is Machine Learning?')\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BHHzKg-HQtO",
        "outputId": "a2752f6a-eb73-44cb-c91b-e816aef461e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that involves training algorithms to learn from data and make predictions or decisions without being explicitly programmed. It's a way to enable computers to automatically improve their performance on a task over time, based on the data they receive.\n",
            "\n",
            "Machine Learning involves several key steps:\n",
            "\n",
            "1. **Data Collection**: Gathering data relevant to the problem you want to solve.\n",
            "2. **Data Preprocessing**: Cleaning, transforming, and preparing the data for training.\n",
            "3. **Model Training**: Training a machine learning algorithm on the preprocessed data.\n",
            "4. **Model Evaluation**: Evaluating the performance of the trained model on a test dataset.\n",
            "5. **Model Deployment**: Deploying the trained model in a production environment.\n",
            "\n",
            "Machine Learning can be categorized into three main types:\n",
            "\n",
            "1. **Supervised Learning**: The algorithm is trained on labeled data, where the correct output is already known. The goal is to learn a mapping between input data and output labels.\n",
            "2. **Unsupervised Learning**: The algorithm is trained on unlabeled data, and the goal is to discover patterns or relationships in the data.\n",
            "3. **Reinforcement Learning**: The algorithm learns through trial and error by interacting with an environment and receiving feedback in the form of rewards or penalties.\n",
            "\n",
            "Some common applications of Machine Learning include:\n",
            "\n",
            "1. **Image Recognition**: Image classification, object detection, and segmentation.\n",
            "2. **Natural Language Processing**: Text classification, sentiment analysis, and language translation.\n",
            "3. **Speech Recognition**: Speech-to-text and voice recognition.\n",
            "4. **Predictive Analytics**: Forecasting and predicting outcomes based on historical data.\n",
            "5. **Recommendation Systems**: Personalized recommendations based on user behavior and preferences.\n",
            "\n",
            "Machine Learning has many benefits, including:\n",
            "\n",
            "1. **Improved Accuracy**: Machine Learning algorithms can outperform traditional rule-based systems.\n",
            "2. **Increased Efficiency**: Automation of tasks and processes.\n",
            "3. **Scalability**: Machine Learning algorithms can handle large datasets and scale to meet growing demands.\n",
            "4. **Flexibility**: Machine Learning algorithms can be applied to a wide range of problems and domains.\n",
            "\n",
            "However, Machine Learning also has some challenges and limitations, including:\n",
            "\n",
            "1. **Data Quality**: Machine Learning algorithms require high-quality data to learn from.\n",
            "2. **Bias and Fairness**: Machine Learning algorithms can perpetuate biases and unfairness if the training data is biased.\n",
            "3. **Explainability**: Machine Learning algorithms can be difficult to interpret and understand.\n",
            "4. **Security**: Machine Learning algorithms can be vulnerable to attacks and data breaches.\n",
            "\n",
            "Overall, Machine Learning is a powerful tool for solving complex problems and making predictions or decisions based on data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain_community beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbZVpmK0HVmc",
        "outputId": "564825ea-51b8-4cc7-dcd4-49a4abd5483b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader=WebBaseLoader('https://jobs.nike.com/job/R-39879?from=job%20search%20funnel')\n",
        "page_data=loader.load().pop().page_content\n",
        "page_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "gETS2KwNHgBs",
        "outputId": "52524686-e264-47e2-e299-b879c557137e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Apply for Machine Learning Engineer - Supply Chain\\n\\nSearch JobsSkip navigationSearch JobsNIKE, INC. JOBSContract JobsJoin The Talent CommunityLife @ NikeOverviewBenefitsBrandsOverviewJordanConverseTeamsOverviewAdministrative SupportAdvanced InnovationAir Manufacturing InnovationAviationCommunicationsCustomer ServiceDesignDigitalFacilitiesFinance & AccountingGovernment & Public AffairsHuman ResourcesInsights & AnalyticsLegalManufacturing & EngineeringMarketingMerchandisingPlanningPrivacyProcurementProduct Creation, Development & ManagementRetail CorporateRetail StoresSalesSocial & Community ImpactSports MarketingStrategic PlanningSupply Chain, Distribution & LogisticsSustainabilityTechnologyLocationsOverviewNike WHQNike New York HQEHQ: Hilversum, The NetherlandsELC: Laakdal, BelgiumGreater China HQDiversity, Equity & InclusionOverviewMilitary InclusionDisability InclusionIndigenous InclusionInternshipsData & AnalyticsMachine Learning Engineer - Supply ChainBeaverton, OregonBecome a Part of the NIKE, Inc. Team\\nNIKE, Inc. does more than outfit the world’s best athletes. It is a place to explore potential, obliterate boundaries and push out the edges of what can be. The company looks for people who can grow, think, dream and create. Its culture thrives by embracing diversity and rewarding imagination. The brand seeks achievers, leaders and visionaries. At NIKE, Inc. it’s about each person bringing skills and passion to a challenging and constantly evolving game.Open to remote work except in South Dakota, Vermont and West Virginia.The annual base salary for this position ranges from $82,900.00 in our lowest geographic market to $185,700.00 in our highest geographic market. Actual salary will vary based on a candidate's location, qualifications, skills and experience.Information about benefits can be found here.\\xa0This posting is for two positions within the Enterprise AI/ML\\xa0function.WHO ARE WE LOOKING FORWe seek passionate engineers to join our team!\\xa0 As a Machine Learning Engineer, you will develop robust advanced analytics and machine learning solutions that have a direct impact on the Supply Chain infrastructure.\\xa0 You should have experience in Python; a strong background in algorithms and data structures; hands-on AWS experience; as well as experience in database technology (e.g. Postgres, Redis) and data processing technology (e.g. EMR).\\xa0 You should also have a demonstrable history of team leadership and value delivery, and be comfortable working in an agile product model.\\xa0 As a ML Engineer, you will be expected to own projects end-to-end - from conception to operationalization, demonstrating an understanding of the full software development lifecycle.\\xa0 As a result, you will be expected to provide technical vision and guidance to your teammates; therefore, strong communication skills are critical in this role.\\xa0WHAT WILL YOU WORK ONIf this is you, you’ll be working with the Artificial Intelligence and Machine Learning (AI/ML) team at Nike.\\xa0 With teammates in Portland, Boston, and Poland, you’ll be joining a global organization working to solve machine learning problems at scale.\\xa0 You’ll be designing and implementing scalable applications that leverage prediction models and optimization programs to deliver data driven decisions that result in immense business impact.\\xa0 You’ll also contribute to core advanced analytics and machine learning platforms and tools to enable both prediction and optimization model development.\\xa0 You thrive when surrounded by talented colleagues and aim to never stop learning. We are looking for candidates who enjoy a collaborative and academic environment where we develop and share new skills, mentor, and contribute knowledge and software back to the analytics and engineering communities both within Nike and at-large.We value and nurture our culture by seeking to always be collaborative, intellectually curious, fun, open, and diverse.WHO WILL YOU WORK WITHIn this role, you’ll be working closely with the rest of our global team, along with commercial and consumer analytics, and enterprise architecture teams. You will report to the director of Supply Chain AI/ML Engineering.WHAT YOU BRING Bachelor's degree in Computer Science, or combination of relevant education, experience.1-3 years of professional experience in software engineering, data engineering, machine learning, or related fieldA demonstrated problem solving and analytical mindsetAbility to write robust, maintainable, and extendable code in Python; containerized in Docker, and automated with CI/CDExperience with agile development and test driven developmentUnderstanding of data structures, data modeling and software architectureExperience with data sets, ETL pipelines, SQL, and general data engineeringExposure to MLOps, API development, or mathematical optimization are highly desirableExperience with cloud architecture and technologies, in particular Amazon Web ServicesExperience with technologies like Spark, Kubernetes, Docker, Jenkins, Databricks, Terraform is also highly desirableEffective communication skills (with team members, the business, and in code)NIKE, Inc. is a growth company that looks for team members to grow with it. Nike offers a generous total rewards package, casual work environment, a diverse and inclusive culture, and an electric atmosphere for professional development. No matter the location, or the role, every Nike employee shares one galvanizing mission: To bring inspiration and innovation to every athlete* in the world.NIKE, Inc. is committed to employing a diverse workforce. Qualified applicants will receive consideration without regard to race, color, religion, sex, national origin, age, sexual orientation, gender identity, gender expression, veteran status, or disability.How We HireAt NIKE, Inc. we promise to provide a premium, inclusive, compelling and authentic candidate experience. Delivering on this promise means we allow you to be at your best — and to do that, you need to understand how the hiring process works. Transparency is key.\\r\\n\\r\\n* This overview explains our hiring process for corporate roles. Note there may be different hiring steps involved for non-corporate roles.Start nowBenefitsWhether it’s transportation or financial health, we continually invest in our employees to help them achieve greatness — inside and outside of work. All who work here should be able to realize their full potential.Employee Assistance ProgramEmployee Stock Purchase Plan (ESPP)HolidaysMedical PlanPaid Time Off (PTO)Product DiscountsSabbaticalsLearn moreGIFT CARDSPROMOTIONSFIND A STORESIGN UP FOR EMAILBECOME A MEMBERNIKE JOURNALSEND US FEEDBACKGET HELPGET HELPOrder StatusShipping and DeliveryReturnsPayment OptionsGift Cards BalanceContact UsABOUT NIKEABOUT NIKENewsCareersInvestorsPurposeSustainabilityUnited States© 2024 Nike, Inc. All Rights ReservedGuidesNike AdaptNike Air MaxNike FlyleatherNike ReactSpace HippieNike AirNike FlyEaseNike Free Nike VaporflyNike Air Force 1 Nike FlyknitNike JoyrideNike ZoomXTerms of SaleTerms of UseNike Privacy PolicyYour Privacy ChoicesCA Supply Chain Act\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "prompt_extract=PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    ###SCRAPED TEXT FROM WEBSITE:\n",
        "    {page_data}\n",
        "    ###INSTRUCTION:\n",
        "    The scraped text is from the career's page of a website.\n",
        "    Your job is to extract the job postings and return theem in JSON format containing\n",
        "    following keys: 'role','experience','skills' and 'descripton'.\n",
        "    Only return the valid JSON.\n",
        "    ###VALID JSON(NO PREAMBLE):\n",
        "    \"\"\"\n",
        ")\n",
        "chain_extract=prompt_extract | llm\n",
        "res=chain_extract.invoke({'page_data': page_data})\n",
        "type(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHzj_e9qHrLe",
        "outputId": "1cabd865-d51f-447a-e861-dccecc5827f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "json_parser=JsonOutputParser()\n",
        "json_res=json_parser.parse(res.content)\n",
        "json_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehyrrH3pHvNz",
        "outputId": "f2d2e827-de9a-4a64-8c5d-1bcdd399e428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'role': 'Machine Learning Engineer - Supply Chain',\n",
              " 'experience': '1-3 years of professional experience in software engineering, data engineering, machine learning, or related field',\n",
              " 'skills': ['Python',\n",
              "  'algorithms and data structures',\n",
              "  'AWS',\n",
              "  'database technology (e.g. Postgres, Redis)',\n",
              "  'data processing technology (e.g. EMR)',\n",
              "  'containerized in Docker',\n",
              "  'automated with CI/CD',\n",
              "  'agile development',\n",
              "  'test driven development',\n",
              "  'MLOps',\n",
              "  'API development',\n",
              "  'mathematical optimization',\n",
              "  'cloud architecture',\n",
              "  'Amazon Web Services',\n",
              "  'Spark',\n",
              "  'Kubernetes',\n",
              "  'Docker',\n",
              "  'Jenkins',\n",
              "  'Databricks',\n",
              "  'Terraform'],\n",
              " 'description': 'Develop robust advanced analytics and machine learning solutions that have a direct impact on the Supply Chain infrastructure. Design and implement scalable applications that leverage prediction models and optimization programs to deliver data driven decisions that result in immense business impact.'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(json_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c_2wSjhHz1Y",
        "outputId": "c5e414c0-ddd6-41a6-c25a-4cba64a1bb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/my_portfolio.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "SGgyIpQEH3aC",
        "outputId": "0e8f2927-528e-484e-c9f0-793bee63eec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Techstack  \\\n",
              "0                React, Node.js, MongoDB   \n",
              "1               Angular,.NET, SQL Server   \n",
              "2      Vue.js, Ruby on Rails, PostgreSQL   \n",
              "3                  Python, Django, MySQL   \n",
              "4              Java, Spring Boot, Oracle   \n",
              "5             Flutter, Firebase, GraphQL   \n",
              "6                  WordPress, PHP, MySQL   \n",
              "7                    Magento, PHP, MySQL   \n",
              "8         React Native, Node.js, MongoDB   \n",
              "9                  iOS, Swift, Core Data   \n",
              "10       Android, Java, Room Persistence   \n",
              "11             Kotlin, Android, Firebase   \n",
              "12       Android TV, Kotlin, Android NDK   \n",
              "13                     iOS, Swift, ARKit   \n",
              "14        Cross-platform, Xamarin, Azure   \n",
              "15          Backend, Kotlin, Spring Boot   \n",
              "16         Frontend, TypeScript, Angular   \n",
              "17    Full-stack, JavaScript, Express.js   \n",
              "18  Machine Learning, Python, TensorFlow   \n",
              "19               DevOps, Jenkins, Docker   \n",
              "\n",
              "                                                Links  \n",
              "0                 https://example.com/react-portfolio  \n",
              "1               https://example.com/angular-portfolio  \n",
              "2                   https://example.com/vue-portfolio  \n",
              "3                https://example.com/python-portfolio  \n",
              "4                  https://example.com/java-portfolio  \n",
              "5               https://example.com/flutter-portfolio  \n",
              "6             https://example.com/wordpress-portfolio  \n",
              "7               https://example.com/magento-portfolio  \n",
              "8          https://example.com/react-native-portfolio  \n",
              "9                   https://example.com/ios-portfolio  \n",
              "10              https://example.com/android-portfolio  \n",
              "11       https://example.com/kotlin-android-portfolio  \n",
              "12           https://example.com/android-tv-portfolio  \n",
              "13               https://example.com/ios-ar-portfolio  \n",
              "14              https://example.com/xamarin-portfolio  \n",
              "15       https://example.com/kotlin-backend-portfolio  \n",
              "16  https://example.com/typescript-frontend-portfolio  \n",
              "17        https://example.com/full-stack-js-portfolio  \n",
              "18            https://example.com/ml-python-portfolio  \n",
              "19               https://example.com/devops-portfolio  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24c738ce-95cd-4e61-984f-ca71c0a26f20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Techstack</th>\n",
              "      <th>Links</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>React, Node.js, MongoDB</td>\n",
              "      <td>https://example.com/react-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Angular,.NET, SQL Server</td>\n",
              "      <td>https://example.com/angular-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vue.js, Ruby on Rails, PostgreSQL</td>\n",
              "      <td>https://example.com/vue-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Python, Django, MySQL</td>\n",
              "      <td>https://example.com/python-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Java, Spring Boot, Oracle</td>\n",
              "      <td>https://example.com/java-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Flutter, Firebase, GraphQL</td>\n",
              "      <td>https://example.com/flutter-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>WordPress, PHP, MySQL</td>\n",
              "      <td>https://example.com/wordpress-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Magento, PHP, MySQL</td>\n",
              "      <td>https://example.com/magento-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>React Native, Node.js, MongoDB</td>\n",
              "      <td>https://example.com/react-native-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>iOS, Swift, Core Data</td>\n",
              "      <td>https://example.com/ios-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Android, Java, Room Persistence</td>\n",
              "      <td>https://example.com/android-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Kotlin, Android, Firebase</td>\n",
              "      <td>https://example.com/kotlin-android-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Android TV, Kotlin, Android NDK</td>\n",
              "      <td>https://example.com/android-tv-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>iOS, Swift, ARKit</td>\n",
              "      <td>https://example.com/ios-ar-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Cross-platform, Xamarin, Azure</td>\n",
              "      <td>https://example.com/xamarin-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Backend, Kotlin, Spring Boot</td>\n",
              "      <td>https://example.com/kotlin-backend-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Frontend, TypeScript, Angular</td>\n",
              "      <td>https://example.com/typescript-frontend-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Full-stack, JavaScript, Express.js</td>\n",
              "      <td>https://example.com/full-stack-js-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Machine Learning, Python, TensorFlow</td>\n",
              "      <td>https://example.com/ml-python-portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>DevOps, Jenkins, Docker</td>\n",
              "      <td>https://example.com/devops-portfolio</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24c738ce-95cd-4e61-984f-ca71c0a26f20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24c738ce-95cd-4e61-984f-ca71c0a26f20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24c738ce-95cd-4e61-984f-ca71c0a26f20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d07234b0-3506-47d6-bbe2-637780562385\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d07234b0-3506-47d6-bbe2-637780562385')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d07234b0-3506-47d6-bbe2-637780562385 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6493a559-b883-4edb-b1b4-0158cc689f5a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6493a559-b883-4edb-b1b4-0158cc689f5a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Techstack\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"React, Node.js, MongoDB\",\n          \"Full-stack, JavaScript, Express.js\",\n          \"Backend, Kotlin, Spring Boot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Links\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"https://example.com/react-portfolio\",\n          \"https://example.com/full-stack-js-portfolio\",\n          \"https://example.com/kotlin-backend-portfolio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XExembZ0IE3A",
        "outputId": "1468fcab-eb0c-43fb-f97e-d2739355e9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.17-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.10)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.2)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.24.7)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.5.17-py3-none-any.whl (615 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.7/615.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=72191b9cf2f0e8ab508874bf2b639d55ba2a62fe4fba2cd148947a14c737d918\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, pyproject_hooks, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, importlib-metadata, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.5.0\n",
            "    Uninstalling importlib_metadata-8.5.0:\n",
            "      Successfully uninstalled importlib_metadata-8.5.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.17 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.4 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.4.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.0 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 posthog-3.7.0 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.41.2 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0 websockets-13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "import uuid\n",
        "client=chromadb.PersistentClient('vectorstore')\n",
        "collection=client.get_or_create_collection(name='portfolio')\n",
        "if not collection.count():\n",
        "  for _,row in df.iterrows():\n",
        "    collection.add(documents=row['Techstack'],\n",
        "                   metadatas={'links': row['Links']},\n",
        "                   ids=[str(uuid.uuid4())])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IemiVFhINPk",
        "outputId": "b1c84bf0-f506-4771-88a7-995ba5c1d983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:02<00:00, 30.7MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "links=collection.query(query_texts=[\"Experience in Python\",\"Expertise in React\"],\n",
        "                       n_results=2).get('metadatas')\n",
        "links"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8m6gQhSIXJ-",
        "outputId": "a1a07f4f-763e-47de-c931-70f98372b25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'links': 'https://example.com/ml-python-portfolio'},\n",
              "  {'links': 'https://example.com/python-portfolio'}],\n",
              " [{'links': 'https://example.com/react-portfolio'},\n",
              "  {'links': 'https://example.com/react-native-portfolio'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job=json_res\n",
        "job['skills']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMvXglbZIeR3",
        "outputId": "ab1ee09a-e0fa-4a10-b79d-263874dcb571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Python',\n",
              " 'algorithms and data structures',\n",
              " 'AWS',\n",
              " 'database technology (e.g. Postgres, Redis)',\n",
              " 'data processing technology (e.g. EMR)',\n",
              " 'containerized in Docker',\n",
              " 'automated with CI/CD',\n",
              " 'agile development',\n",
              " 'test driven development',\n",
              " 'MLOps',\n",
              " 'API development',\n",
              " 'mathematical optimization',\n",
              " 'cloud architecture',\n",
              " 'Amazon Web Services',\n",
              " 'Spark',\n",
              " 'Kubernetes',\n",
              " 'Docker',\n",
              " 'Jenkins',\n",
              " 'Databricks',\n",
              " 'Terraform']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "links=collection.query(query_texts=job['skills'],\n",
        "                       n_results=2).get('metadatas')\n",
        "links"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqdbBL2iIj3_",
        "outputId": "0e59466a-2fff-4f4d-a649-c170ac883748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'links': 'https://example.com/ml-python-portfolio'},\n",
              "  {'links': 'https://example.com/python-portfolio'}],\n",
              " [{'links': 'https://example.com/ml-python-portfolio'},\n",
              "  {'links': 'https://example.com/magento-portfolio'}],\n",
              " [{'links': 'https://example.com/ios-ar-portfolio'},\n",
              "  {'links': 'https://example.com/wordpress-portfolio'}],\n",
              " [{'links': 'https://example.com/magento-portfolio'},\n",
              "  {'links': 'https://example.com/vue-portfolio'}],\n",
              " [{'links': 'https://example.com/ml-python-portfolio'},\n",
              "  {'links': 'https://example.com/magento-portfolio'}],\n",
              " [{'links': 'https://example.com/devops-portfolio'},\n",
              "  {'links': 'https://example.com/ios-ar-portfolio'}],\n",
              " [{'links': 'https://example.com/devops-portfolio'},\n",
              "  {'links': 'https://example.com/magento-portfolio'}],\n",
              " [{'links': 'https://example.com/ios-ar-portfolio'},\n",
              "  {'links': 'https://example.com/devops-portfolio'}],\n",
              " [{'links': 'https://example.com/devops-portfolio'},\n",
              "  {'links': 'https://example.com/ml-python-portfolio'}],\n",
              " [{'links': 'https://example.com/devops-portfolio'},\n",
              "  {'links': 'https://example.com/ml-python-portfolio'}],\n",
              " [{'links': 'https://example.com/flutter-portfolio'},\n",
              "  {'links': 'https://example.com/ios-ar-portfolio'}],\n",
              " [{'links': 'https://example.com/ml-python-portfolio'},\n",
              "  {'links': 'https://example.com/wordpress-portfolio'}],\n",
              " [{'links': 'https://example.com/xamarin-portfolio'},\n",
              "  {'links': 'https://example.com/ios-portfolio'}],\n",
              " [{'links': 'https://example.com/wordpress-portfolio'},\n",
              "  {'links': 'https://example.com/magento-portfolio'}],\n",
              " [{'links': 'https://example.com/kotlin-android-portfolio'},\n",
              "  {'links': 'https://example.com/kotlin-backend-portfolio'}],\n",
              " [{'links': 'https://example.com/devops-portfolio'},\n",
              "  {'links': 'https://example.com/kotlin-backend-portfolio'}],\n",
              " [{'links': 'https://example.com/devops-portfolio'},\n",
              "  {'links': 'https://example.com/ios-ar-portfolio'}],\n",
              " [{'links': 'https://example.com/devops-portfolio'},\n",
              "  {'links': 'https://example.com/kotlin-backend-portfolio'}],\n",
              " [{'links': 'https://example.com/flutter-portfolio'},\n",
              "  {'links': 'https://example.com/kotlin-android-portfolio'}],\n",
              " [{'links': 'https://example.com/devops-portfolio'},\n",
              "  {'links': 'https://example.com/kotlin-backend-portfolio'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_email=PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    ### JOB DESCRIPTION:\n",
        "    {job_description}\n",
        "\n",
        "    ### INSTRUCTION:\n",
        "    You are Mohan, a business development executive at AtliQ. AtliQ is an AI & Software Consulting company dedicated to facilitating\n",
        "        the seamless integration of business processes through automated tools.\n",
        "        Over our experience, we have empowered numerous enterprises with tailored solutions, fostering scalability,\n",
        "        process optimization, cost reduction, and heightened overall efficiency.\n",
        "        Your job is to write a cold email to the client regarding the job mentioned above describing the capability of AtliQ\n",
        "        in fulfilling their needs.\n",
        "        Also add the most relevant ones from the following links to showcase Atliq's portfolio: {link_list}\n",
        "        Remember you are Mohan, BDE at AtliQ.\n",
        "        Do not provide a preamble.\n",
        "        ### EMAIL (NO PREAMBLE):\n",
        "\n",
        "        \"\"\"\n",
        ")\n",
        "chain_email=prompt_email | llm\n",
        "res=chain_email.invoke({'job_description': str(job),\n",
        "                        'link_list': links})\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmOC4WzhIj8n",
        "outputId": "de3e418a-3f7d-4601-8808-66a84c161385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Expert Machine Learning Solutions for Supply Chain Optimization\n",
            "\n",
            "Dear Hiring Manager,\n",
            "\n",
            "I came across the job description for a Machine Learning Engineer - Supply Chain at your esteemed organization, and I was impressed by the role's focus on developing advanced analytics and machine learning solutions to drive business impact. As a Business Development Executive at AtliQ, I'd like to introduce our company's capabilities in fulfilling your needs.\n",
            "\n",
            "AtliQ is an AI & Software Consulting company dedicated to facilitating the seamless integration of business processes through automated tools. Our team of experts has extensive experience in designing and implementing scalable applications that leverage prediction models and optimization programs to deliver data-driven decisions.\n",
            "\n",
            "Our expertise aligns with the skills required for the role, including:\n",
            "\n",
            "* Python programming\n",
            "* Algorithms and data structures\n",
            "* AWS and cloud architecture\n",
            "* Database technology (e.g., Postgres, Redis)\n",
            "* Data processing technology (e.g., EMR)\n",
            "* Containerization using Docker\n",
            "* Automated CI/CD pipelines\n",
            "* Agile development and test-driven development\n",
            "* MLOps and API development\n",
            "\n",
            "We've successfully delivered projects that showcase our capabilities in machine learning and Python development. I'd like to share a few examples from our portfolio:\n",
            "\n",
            "* https://example.com/ml-python-portfolio\n",
            "* https://example.com/python-portfolio\n",
            "* https://example.com/devops-portfolio\n",
            "\n",
            "These projects demonstrate our ability to develop robust advanced analytics and machine learning solutions that drive business impact. Our team is well-versed in leveraging mathematical optimization, Spark, Kubernetes, and other technologies to deliver scalable and efficient solutions.\n",
            "\n",
            "If you're looking for a partner to help you develop and implement machine learning solutions that optimize your supply chain infrastructure, I'd be delighted to discuss how AtliQ can support your goals. Please feel free to reply to this email or schedule a call at your convenience.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "Mohan\n",
            "Business Development Executive\n",
            "AtliQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjs37sKAI089",
        "outputId": "43b20f32-9a95-455f-8503-cff81578dbc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.4)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.2)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, huggingface-hub, safehttpx, gradio-client, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 13.1\n",
            "    Uninstalling websockets-13.1:\n",
            "      Successfully uninstalled websockets-13.1\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed aiofiles-23.2.1 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 huggingface-hub-0.26.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.2 safehttpx-0.1.1 semantic-version-2.10.0 tomlkit-0.12.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import re\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<[^>]*?>', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    # Trim leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "class Portfolio:\n",
        "    def __init__(self, file_path=\"/content/my_portfolio.csv\"):\n",
        "        self.file_path = file_path\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.chroma_client = chromadb.PersistentClient('vectorstore')\n",
        "        self.collection = self.chroma_client.get_or_create_collection(name=\"portfolio\")\n",
        "\n",
        "    def load_portfolio(self):\n",
        "        if not self.collection.count():\n",
        "            for _, row in self.data.iterrows():\n",
        "                self.collection.add(documents=row[\"Techstack\"],\n",
        "                                    metadatas={\"links\": row[\"Links\"]},\n",
        "                                    ids=[str(uuid.uuid4())])\n",
        "\n",
        "    def query_links(self, skills):\n",
        "        return self.collection.query(query_texts=skills, n_results=2).get('metadatas', [])\n",
        "\n",
        "class Chain:\n",
        "    def __init__(self):\n",
        "        GROQ_API_KEY='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'\n",
        "        os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "        self.llm = ChatGroq(temperature=0, groq_api_key=os.getenv(\"GROQ_API_KEY\"), model_name=\"llama-3.1-70b-versatile\")\n",
        "\n",
        "    def extract_jobs(self, cleaned_text):\n",
        "        prompt_extract = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            ### SCRAPED TEXT FROM WEBSITE:\n",
        "            {page_data}\n",
        "            ### INSTRUCTION:\n",
        "            The scraped text is from the career's page of a website.\n",
        "            Your job is to extract the job postings and return them in JSON format containing the following keys: `role`, `experience`, `skills` and `description`.\n",
        "            Only return the valid JSON.\n",
        "            ### VALID JSON (NO PREAMBLE):\n",
        "            \"\"\"\n",
        "        )\n",
        "        chain_extract = prompt_extract | self.llm\n",
        "        res = chain_extract.invoke(input={\"page_data\": cleaned_text})\n",
        "        try:\n",
        "            json_parser = JsonOutputParser()\n",
        "            res = json_parser.parse(res.content)\n",
        "        except OutputParserException:\n",
        "            raise OutputParserException(\"Context too big. Unable to parse jobs.\")\n",
        "        return res if isinstance(res, list) else [res]\n",
        "\n",
        "    def write_mail(self, job, links):\n",
        "        prompt_email = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            ### JOB DESCRIPTION:\n",
        "            {job_description}\n",
        "\n",
        "            ### INSTRUCTION:\n",
        "            You are Mohan, a business development executive at AtliQ. AtliQ is an AI & Software Consulting company dedicated to facilitating\n",
        "            the seamless integration of business processes through automated tools.\n",
        "            Over our experience, we have empowered numerous enterprises with tailored solutions, fostering scalability,\n",
        "            process optimization, cost reduction, and heightened overall efficiency.\n",
        "            Your job is to write a cold email to the client regarding the job mentioned above describing the capability of AtliQ\n",
        "            in fulfilling their needs.\n",
        "            Also add the most relevant ones from the following links to showcase Atliq's portfolio: {link_list}\n",
        "            Remember you are Mohan, BDE at AtliQ.\n",
        "            Do not provide a preamble.\n",
        "            ### EMAIL (NO PREAMBLE):\n",
        "\n",
        "            \"\"\"\n",
        "        )\n",
        "        chain_email = prompt_email | self.llm\n",
        "        res = chain_email.invoke({\"job_description\": str(job), \"link_list\": links})\n",
        "        return res.content\n",
        "\n",
        "\n",
        "def generate_email(url):\n",
        "    try:\n",
        "        loader = WebBaseLoader([url])\n",
        "        data = clean_text(loader.load().pop().page_content)\n",
        "        portfolio.load_portfolio()\n",
        "        jobs = chain.extract_jobs(data)\n",
        "        emails = []\n",
        "        for job in jobs:\n",
        "            skills = job.get('skills', [])\n",
        "            links = portfolio.query_links(skills)\n",
        "            email = chain.write_mail(job, links)\n",
        "            emails.append(email)\n",
        "        return \"\\n\\n\".join(emails)\n",
        "    except Exception as e:\n",
        "        return f\"An Error Occurred: {e}\"\n",
        "\n",
        "# Initialize your classes\n",
        "chain = Chain()\n",
        "portfolio = Portfolio()\n",
        "\n",
        "# Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_email,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Cold Mail Generator\",\n",
        "    description=\"Enter a job URL to generate a personalized cold email.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "OHA1rR33I6d0",
        "outputId": "a3fff5fb-9713-44d6-d782-c44cbedbd3e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c8bd5366db1fa20d96.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c8bd5366db1fa20d96.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import re\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<[^>]*?>', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    # Trim leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "class Portfolio:\n",
        "    def __init__(self, file_path=\"/content/my_portfolio.csv\"):\n",
        "        self.file_path = file_path\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.chroma_client = chromadb.PersistentClient('vectorstore')\n",
        "        self.collection = self.chroma_client.get_or_create_collection(name=\"portfolio\")\n",
        "\n",
        "    def load_portfolio(self):\n",
        "        if not self.collection.count():\n",
        "            for _, row in self.data.iterrows():\n",
        "                self.collection.add(documents=row[\"Techstack\"],\n",
        "                                    metadatas={\"links\": row[\"Links\"]},\n",
        "                                    ids=[str(uuid.uuid4())])\n",
        "\n",
        "    def query_links(self, skills):\n",
        "        return self.collection.query(query_texts=skills, n_results=2).get('metadatas', [])\n",
        "\n",
        "class Chain:\n",
        "    def __init__(self):\n",
        "        GROQ_API_KEY='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'\n",
        "        os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "        self.llm = ChatGroq(temperature=0, groq_api_key=os.getenv(\"GROQ_API_KEY\"), model_name=\"llama-3.1-70b-versatile\")\n",
        "\n",
        "    def extract_jobs(self, cleaned_text):\n",
        "        prompt_extract = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            ### SCRAPED TEXT FROM WEBSITE:\n",
        "            {page_data}\n",
        "            ### INSTRUCTION:\n",
        "            The scraped text is from the career's page of a website.\n",
        "            Your job is to extract the job postings and return them in JSON format containing the following keys: `role`, `experience`, `skills` and `description`.\n",
        "            Only return the valid JSON.\n",
        "            ### VALID JSON (NO PREAMBLE):\n",
        "            \"\"\"\n",
        "        )\n",
        "        chain_extract = prompt_extract | self.llm\n",
        "        res = chain_extract.invoke(input={\"page_data\": cleaned_text})\n",
        "        try:\n",
        "            json_parser = JsonOutputParser()\n",
        "            res = json_parser.parse(res.content)\n",
        "        except OutputParserException:\n",
        "            raise OutputParserException(\"Context too big. Unable to parse jobs.\")\n",
        "        return res if isinstance(res, list) else [res]\n",
        "\n",
        "    def write_mail(self, job, links, user_name, recipient_name, email_style):\n",
        "        prompt_email = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            ### JOB DESCRIPTION:\n",
        "            {job_description}\n",
        "\n",
        "            ### INSTRUCTION:\n",
        "            You are {user_name}, a business development executive at AtliQ.\n",
        "            Craft a cold email to {recipient_name} regarding the job mentioned above.\n",
        "            The tone should be {email_style}.\n",
        "            Add the most relevant links to showcase AtliQ's portfolio: {links}.\n",
        "            Do not provide a preamble.\n",
        "            ### EMAIL (NO PREAMBLE):\n",
        "            \"\"\"\n",
        "        )\n",
        "        chain_email = prompt_email | self.llm\n",
        "        res = chain_email.invoke({\"job_description\": str(job), \"user_name\": user_name, \"recipient_name\": recipient_name, \"email_style\": email_style, \"links\": links})\n",
        "        return res.content\n",
        "\n",
        "def generate_subject_line(job):\n",
        "    return f\"Exciting Opportunity for {job['role']} at AtliQ\"\n",
        "\n",
        "def generate_email(url, user_name, recipient_name, email_style):\n",
        "    try:\n",
        "        loader = WebBaseLoader([url])\n",
        "        data = clean_text(loader.load().pop().page_content)\n",
        "        portfolio.load_portfolio()\n",
        "        jobs = chain.extract_jobs(data)\n",
        "        emails = []\n",
        "        job_summaries = []\n",
        "\n",
        "        for job in jobs:\n",
        "            skills = job.get('skills', [])\n",
        "            links = portfolio.query_links(skills)\n",
        "            email = chain.write_mail(job, links, user_name, recipient_name, email_style)\n",
        "            emails.append(email)\n",
        "            job_summaries.append(f\"Role: {job['role']}, Skills: {', '.join(job['skills'])}\")\n",
        "\n",
        "        subject = generate_subject_line(jobs[0]) if jobs else \"No Job Found\"\n",
        "        return subject, \"\\n\\n\".join(emails), \"\\n\".join(job_summaries)\n",
        "    except Exception as e:\n",
        "        return \"Error generating email\", f\"An Error Occurred: {e}\", \"\"\n",
        "\n",
        "# Initialize your classes\n",
        "chain = Chain()\n",
        "portfolio = Portfolio()\n",
        "\n",
        "# Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_email,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Job URL\"),\n",
        "        gr.Textbox(label=\"Your Name\"),\n",
        "        gr.Textbox(label=\"Recipient's Name\"),\n",
        "        gr.Dropdown(label=\"Email Style\", choices=[\"Formal\", \"Informal\"], value=\"Formal\")\n",
        "    ],\n",
        "    outputs=[\"text\", \"text\", \"text\"],\n",
        "    title=\"Cold Mail Generator\",\n",
        "    description=\"Enter a job URL and your details to generate personalized cold emails.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "BeIx2oqrJBlm",
        "outputId": "1c956437-a1c0-4921-c1e0-5b435a707760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f10e9b663f6686d401.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f10e9b663f6686d401.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import re\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<[^>]*?>', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    # Trim leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "class Portfolio:\n",
        "    def __init__(self, file_path=\"/content/my_portfolio.csv\"):\n",
        "        self.file_path = file_path\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.chroma_client = chromadb.PersistentClient('vectorstore')\n",
        "        self.collection = self.chroma_client.get_or_create_collection(name=\"portfolio\")\n",
        "\n",
        "    def load_portfolio(self):\n",
        "        if not self.collection.count():\n",
        "            for _, row in self.data.iterrows():\n",
        "                self.collection.add(documents=row[\"Techstack\"],\n",
        "                                    metadatas={\"links\": row[\"Links\"]},\n",
        "                                    ids=[str(uuid.uuid4())])\n",
        "\n",
        "    def query_links(self, skills):\n",
        "        return self.collection.query(query_texts=skills, n_results=2).get('metadatas', [])\n",
        "\n",
        "class Chain:\n",
        "    def __init__(self):\n",
        "        GROQ_API_KEY='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'\n",
        "        os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "        self.llm = ChatGroq(temperature=0, groq_api_key=os.getenv(\"GROQ_API_KEY\"), model_name=\"llama-3.1-70b-versatile\")\n",
        "\n",
        "    def extract_jobs(self, cleaned_text):\n",
        "        prompt_extract = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            ### SCRAPED TEXT FROM WEBSITE:\n",
        "            {page_data}\n",
        "            ### INSTRUCTION:\n",
        "            The scraped text is from the career's page of a website.\n",
        "            Your job is to extract the job postings and return them in JSON format containing the following keys: role, experience, skills and description.\n",
        "            Only return the valid JSON.\n",
        "            ### VALID JSON (NO PREAMBLE):\n",
        "            \"\"\"\n",
        "        )\n",
        "        chain_extract = prompt_extract | self.llm\n",
        "        res = chain_extract.invoke(input={\"page_data\": cleaned_text})\n",
        "        try:\n",
        "            json_parser = JsonOutputParser()\n",
        "            res = json_parser.parse(res.content)\n",
        "        except OutputParserException:\n",
        "            raise OutputParserException(\"Context too big. Unable to parse jobs.\")\n",
        "        return res if isinstance(res, list) else [res]\n",
        "\n",
        "    def write_mail(self, job, links, user_name, recipient_name, email_style):\n",
        "        prompt_email = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            ### JOB DESCRIPTION:\n",
        "            {job_description}\n",
        "\n",
        "            ### INSTRUCTION:\n",
        "            You are {user_name}, a business development executive at AtliQ.\n",
        "            Craft a cold email to {recipient_name} regarding the job mentioned above.\n",
        "            The tone should be {email_style}.\n",
        "            Add the most relevant links to showcase AtliQ's portfolio: {links}.\n",
        "            Do not provide a preamble.\n",
        "            ### EMAIL (NO PREAMBLE):\n",
        "            \"\"\"\n",
        "        )\n",
        "        chain_email = prompt_email | self.llm\n",
        "        res = chain_email.invoke({\"job_description\": str(job), \"user_name\": user_name, \"recipient_name\": recipient_name, \"email_style\": email_style, \"links\": links})\n",
        "        return res.content\n",
        "\n",
        "def generate_subject_line(job):\n",
        "    return f\"Exciting Opportunity for {job['role']} at AtliQ\"\n",
        "\n",
        "def generate_email(url, user_name, recipient_name, email_style, uploaded_file):\n",
        "    try:\n",
        "        loader = WebBaseLoader([url])\n",
        "        data = clean_text(loader.load().pop().page_content)\n",
        "        portfolio.load_portfolio()\n",
        "        jobs = chain.extract_jobs(data)\n",
        "        emails = []\n",
        "        job_summaries = []\n",
        "\n",
        "        for job in jobs:\n",
        "            skills = job.get('skills', [])\n",
        "            links = portfolio.query_links(skills)\n",
        "            email = chain.write_mail(job, links, user_name, recipient_name, email_style)\n",
        "            emails.append(email)\n",
        "            job_summaries.append(f\"Role: {job['role']}, Skills: {', '.join(job['skills'])}\")\n",
        "\n",
        "        subject = generate_subject_line(jobs[0]) if jobs else \"No Job Found\"\n",
        "        return subject, \"\\n\\n\".join(emails), \"\\n\".join(job_summaries)\n",
        "    except Exception as e:\n",
        "        return \"Error generating email\", f\"An Error Occurred: {e}\", \"\"\n",
        "\n",
        "# Initialize your classes\n",
        "chain = Chain()\n",
        "portfolio = Portfolio()\n",
        "\n",
        "# Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_email,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Job URL\"),\n",
        "        gr.Textbox(label=\"Your Name\"),\n",
        "        gr.Textbox(label=\"Recipient's Name\"),\n",
        "        gr.Dropdown(label=\"Email Style\", choices=[\"Formal\", \"Informal\"], value=\"Formal\"),\n",
        "        gr.File(label=\"Upload Your Resume or Portfolio\")  # File upload for attachments\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Subject Line\", interactive=False),\n",
        "        gr.Markdown(label=\"Generated Email Preview\"),  # Preview of the email\n",
        "        gr.Textbox(label=\"Job Summary\", interactive=False)\n",
        "    ],\n",
        "    title=\"Cold Mail Generator\",\n",
        "    description=\"Enter a job URL and your details to generate personalized cold emails.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "T2gpyxhGKeky",
        "outputId": "86d5b684-c70f-474e-b0e4-a28d1f396f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://09f4a2b27d19fd8f5f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://09f4a2b27d19fd8f5f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import re\n",
        "import uuid\n",
        "import pandas as pd\n",
        "import chromadb\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<[^>]*?>', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    # Trim leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "class Portfolio:\n",
        "    def __init__(self, file_path=\"/content/my_portfolio.csv\"):\n",
        "        self.file_path = file_path\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.chroma_client = chromadb.PersistentClient('vectorstore')\n",
        "        self.collection = self.chroma_client.get_or_create_collection(name=\"portfolio\")\n",
        "\n",
        "    def load_portfolio(self):\n",
        "        if not self.collection.count():\n",
        "            for _, row in self.data.iterrows():\n",
        "                self.collection.add(documents=row[\"Techstack\"],\n",
        "                                    metadatas={\"links\": row[\"Links\"]},\n",
        "                                    ids=[str(uuid.uuid4())])\n",
        "\n",
        "    def query_links(self, skills):\n",
        "        return self.collection.query(query_texts=skills, n_results=2).get('metadatas', [])\n",
        "\n",
        "class Chain:\n",
        "    def __init__(self):\n",
        "        GROQ_API_KEY='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'\n",
        "        os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "        self.llm = ChatGroq(temperature=0, groq_api_key=os.getenv(\"GROQ_API_KEY\"), model_name=\"llama-3.1-70b-versatile\")\n",
        "\n",
        "    def extract_jobs(self, cleaned_text):\n",
        "        prompt_extract = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            ### SCRAPED TEXT FROM WEBSITE:\n",
        "            {page_data}\n",
        "            ### INSTRUCTION:\n",
        "            The scraped text is from the career's page of a website.\n",
        "            Your job is to extract the job postings and return them in JSON format containing the following keys: role, experience, skills and description.\n",
        "            Only return the valid JSON.\n",
        "            ### VALID JSON (NO PREAMBLE):\n",
        "            \"\"\"\n",
        "        )\n",
        "        chain_extract = prompt_extract | self.llm\n",
        "        res = chain_extract.invoke(input={\"page_data\": cleaned_text})\n",
        "        try:\n",
        "            json_parser = JsonOutputParser()\n",
        "            res = json_parser.parse(res.content)\n",
        "        except OutputParserException:\n",
        "            raise OutputParserException(\"Context too big. Unable to parse jobs.\")\n",
        "        return res if isinstance(res, list) else [res]\n",
        "\n",
        "    def write_mail(self, job, links, user_name, recipient_name, email_style):\n",
        "        prompt_email = PromptTemplate.from_template(\n",
        "            \"\"\"\n",
        "            ### JOB DESCRIPTION:\n",
        "            {job_description}\n",
        "\n",
        "            ### INSTRUCTION:\n",
        "            You are {user_name}, a business development executive at AtliQ.\n",
        "            Craft a cold email to {recipient_name} regarding the job mentioned above.\n",
        "            The tone should be {email_style}.\n",
        "            Add the most relevant links to showcase AtliQ's portfolio: {links}.\n",
        "            Do not provide a preamble.\n",
        "            ### EMAIL (NO PREAMBLE):\n",
        "            \"\"\"\n",
        "        )\n",
        "        chain_email = prompt_email | self.llm\n",
        "        res = chain_email.invoke({\"job_description\": str(job), \"user_name\": user_name, \"recipient_name\": recipient_name, \"email_style\": email_style, \"links\": links})\n",
        "        return res.content\n",
        "\n",
        "def generate_subject_line(job):\n",
        "    return f\"Exciting Opportunity for {job['role']} at AtliQ\"\n",
        "\n",
        "def generate_email(url, user_name, recipient_name, email_style, uploaded_file):\n",
        "    try:\n",
        "        # Load job data from the URL\n",
        "        loader = WebBaseLoader([url])\n",
        "        data = clean_text(loader.load().pop().page_content)\n",
        "        portfolio.load_portfolio()\n",
        "        jobs = chain.extract_jobs(data)\n",
        "        emails = []\n",
        "        job_summaries = []\n",
        "\n",
        "        for job in jobs:\n",
        "            skills = job.get('skills', [])\n",
        "            links = portfolio.query_links(skills)\n",
        "            email = chain.write_mail(job, links, user_name, recipient_name, email_style)\n",
        "            emails.append(email)\n",
        "            job_summaries.append(f\"Role: {job['role']}, Skills: {', '.join(job['skills'])}\")\n",
        "\n",
        "        subject = generate_subject_line(jobs[0]) if jobs else \"No Job Found\"\n",
        "        # Include uploaded file name in the response\n",
        "        attachment = f\"Attached: {uploaded_file.name}\" if uploaded_file else \"No attachment included.\"\n",
        "        return subject, \"\\n\\n\".join(emails), \"\\n\".join(job_summaries), attachment\n",
        "    except Exception as e:\n",
        "        return \"Error generating email\", f\"An Error Occurred: {e}\", \"\", \"\"\n",
        "\n",
        "# Initialize your classes\n",
        "chain = Chain()\n",
        "portfolio = Portfolio()\n",
        "\n",
        "# Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_email,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Job URL\"),\n",
        "        gr.Textbox(label=\"Your Name\"),\n",
        "        gr.Textbox(label=\"Recipient's Name\"),\n",
        "        gr.Dropdown(label=\"Email Style\", choices=[\"Formal\", \"Informal\"], value=\"Formal\"),\n",
        "        gr.File(label=\"Upload Your Resume or Portfolio\")  # File upload for attachments\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Subject Line\", interactive=False),\n",
        "        gr.Markdown(label=\"Generated Email Preview\"),  # Preview of the email\n",
        "        gr.Textbox(label=\"Job Summary\", interactive=False),\n",
        "        gr.Textbox(label=\"Attachment Status\", interactive=False)  # Show attachment status\n",
        "    ],\n",
        "    title=\"Cold Mail Generator\",\n",
        "    description=\"Enter a job URL and your details to generate personalized cold emails.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "LVRxjZOYL3ce",
        "outputId": "fd0d6aba-99a1-4a6d-fed1-5726ef3ed609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://16e987edb57bc30d76.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://16e987edb57bc30d76.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}